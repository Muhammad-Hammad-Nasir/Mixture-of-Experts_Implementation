{"cells":[{"cell_type":"markdown","id":"oXG9Br59kAmR","metadata":{"id":"oXG9Br59kAmR"},"source":["# Task 1: Comparing the Implementation of Phixtral and Mixtral"]},{"cell_type":"markdown","id":"FKmkpI5cj-TO","metadata":{"id":"FKmkpI5cj-TO"},"source":["### **Resources:**\n","**Phixtral:** https://huggingface.co/mlabonne/phixtral-2x2_8  \n","**Mixtral:** https://huggingface.co/mistralai/Mixtral-8x7B-v0.1  \n","**Mixtral Instruction Tuned:** https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1"]},{"cell_type":"markdown","id":"ui98hbJAKHVF","metadata":{"id":"ui98hbJAKHVF"},"source":["# Task 2: Implementing MoE as a Task Expert"]},{"cell_type":"markdown","id":"OMugDA8DKBa3","metadata":{"id":"OMugDA8DKBa3"},"source":["**Code by:** Dr. Shahriar Hossain <br>\n","**Video explaining this code:** https://youtu.be/3MX4RJbGIVQ <br>\n"]},{"cell_type":"markdown","id":"3DCoPYuckl-C","metadata":{"id":"3DCoPYuckl-C"},"source":["**Note:** No GPU required for this implementation."]},{"cell_type":"markdown","id":"4ZzufYEeKKpO","metadata":{"id":"4ZzufYEeKKpO"},"source":["## Import Dependencies"]},{"cell_type":"code","execution_count":null,"id":"b70a7041-53d9-4305-bdb0-d22173b50a95","metadata":{"id":"b70a7041-53d9-4305-bdb0-d22173b50a95"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"markdown","id":"q-IoPpS1KktS","metadata":{"id":"q-IoPpS1KktS"},"source":["## Expert Model"]},{"cell_type":"code","execution_count":null,"id":"208619ce-0270-4e6d-b30f-90107432e0ba","metadata":{"id":"208619ce-0270-4e6d-b30f-90107432e0ba"},"outputs":[],"source":["# Define the expert model\n","class Expert(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(Expert, self).__init__()\n","        self.layer1 = nn.Linear(input_dim, hidden_dim)\n","        self.layer2 = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.layer1(x))\n","        return torch.softmax(self.layer2(x), dim=1)\n"]},{"cell_type":"markdown","id":"BBisRRcOKxCQ","metadata":{"id":"BBisRRcOKxCQ"},"source":["## Gating Model\n","The Gating class selects the most relevant expert for a given input."]},{"cell_type":"code","execution_count":null,"id":"078fb12a-60d5-4e5f-8d72-a49d01aa9291","metadata":{"id":"078fb12a-60d5-4e5f-8d72-a49d01aa9291"},"outputs":[],"source":["# Define the gating model\n","class Gating(nn.Module):\n","    def __init__(self, input_dim, num_experts, dropout_rate=0.1):\n","        super(Gating, self).__init__()\n","\n","        # Layers\n","        self.layer1 = nn.Linear(input_dim, 128)\n","        self.dropout1 = nn.Dropout(dropout_rate)\n","\n","        self.layer2 = nn.Linear(128, 256)\n","        self.leaky_relu1 = nn.LeakyReLU()\n","        self.dropout2 = nn.Dropout(dropout_rate)\n","\n","        self.layer3 = nn.Linear(256, 128)\n","        self.leaky_relu2 = nn.LeakyReLU()\n","        self.dropout3 = nn.Dropout(dropout_rate)\n","\n","        self.layer4 = nn.Linear(128, num_experts)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.layer1(x))\n","        x = self.dropout1(x)\n","\n","        x = self.layer2(x)\n","        x = self.leaky_relu1(x)\n","        x = self.dropout2(x)\n","\n","        x = self.layer3(x)\n","        x = self.leaky_relu2(x)\n","        x = self.dropout3(x)\n","\n","        return torch.softmax(self.layer4(x), dim=1)\n"]},{"cell_type":"markdown","id":"4_aJNYhFLKB3","metadata":{"id":"4_aJNYhFLKB3"},"source":["## MoE Model:\n","\n","The MoE model combines multiple trained experts using a gating mechanism.\n","By adjusting weights and aggregating outputs, it generates a unified prediction."]},{"cell_type":"code","execution_count":null,"id":"ba02da85","metadata":{"id":"ba02da85"},"outputs":[],"source":["# Define the MoE model\n","class MoE(nn.Module):\n","    def __init__(self, trained_experts):\n","        super(MoE, self).__init__()\n","        self.experts = nn.ModuleList(trained_experts)\n","\n","        # Freezing the experts to ensure that they are not\n","        # learning when MoE is training.\n","        # Ideally, one can free them before sending the\n","        # experts to the MoE; in that case the following three\n","        # lines can be commented out.\n","        for expert in self.experts:\n","            for param in expert.parameters():\n","                param.requires_grad = False\n","\n","        num_experts = len(trained_experts)\n","        # Assuming all experts have the same input dimension\n","        input_dim = trained_experts[0].layer1.in_features\n","        self.gating = nn.Linear(input_dim, num_experts)\n","\n","    def forward(self, x):\n","        # Get the weights from the gating network\n","        weights = self.gating(x)\n","\n","        # Calculate the expert outputs\n","        outputs = torch.stack(\n","            [expert(x) for expert in self.experts], dim=2)\n","\n","        # Adjust the weights tensor shape to match the expert outputs\n","        weights = weights.unsqueeze(1).expand_as(outputs)\n","\n","        # Multiply the expert outputs with the weights and\n","        # sum along the third dimension\n","        return torch.sum(outputs * weights, dim=2)"]},{"cell_type":"markdown","id":"yi4wY-WDLcDw","metadata":{"id":"yi4wY-WDLcDw"},"source":["## Generate Dataset"]},{"cell_type":"code","execution_count":null,"id":"m7WLOYOMOCQq","metadata":{"id":"m7WLOYOMOCQq"},"outputs":[],"source":["# Generate the dataset\n","num_samples = 5000\n","input_dim = 4\n","hidden_dim = 32\n","\n","# Generate equal numbers of labels 0, 1, and 2\n","y_data = torch.cat([\n","    torch.zeros(num_samples // 3),\n","    torch.ones(num_samples // 3),\n","    torch.full((num_samples - 2 * (num_samples // 3),), 2)  # Filling the remaining to ensure exact num_samples\n","]).long()\n","\n","# Biasing the data based on the labels\n","x_data = torch.randn(num_samples, input_dim)\n","\n","for i in range(num_samples):\n","    if y_data[i] == 0:\n","        x_data[i, 0] += 1  # Making x[0] more positive\n","    elif y_data[i] == 1:\n","        x_data[i, 1] -= 1  # Making x[1] more negative\n","    elif y_data[i] == 2:\n","        x_data[i, 0] -= 1  # Making x[0] more negative"]},{"cell_type":"code","execution_count":null,"id":"RJyoVPGCOZXp","metadata":{"id":"RJyoVPGCOZXp","outputId":"1c09e153-3f54-4ab4-984d-808fe2c72927"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1666, 1666, 1668])\n"]}],"source":["# Shuffle the data to randomize the order\n","indices = torch.randperm(num_samples)\n","x_data = x_data[indices]\n","y_data = y_data[indices]\n","\n","# Verify the label distribution\n","print(y_data.bincount())\n","\n","# Shuffle the data to ensure x data and y data remain aligned\n","shuffled_indices = torch.randperm(num_samples)\n","x_data = x_data[shuffled_indices]\n","y_data = y_data[shuffled_indices]\n","\n","# Splitting data for training individual experts\n","# Use the first half samples for training individual experts\n","x_train_experts = x_data[:int(num_samples/2)]\n","y_train_experts = y_data[:int(num_samples/2)]\n","\n","mask_expert1 = (y_train_experts == 0) | (y_train_experts == 1)\n","mask_expert2 = (y_train_experts == 1) | (y_train_experts == 2)\n","mask_expert3 = (y_train_experts == 0) | (y_train_experts == 2)"]},{"cell_type":"code","execution_count":null,"id":"77Y_K9dVOcry","metadata":{"id":"77Y_K9dVOcry"},"outputs":[],"source":["# Select an almost equal number of samples for each expert\n","num_samples_per_expert = \\\n","min(mask_expert1.sum(), mask_expert2.sum(), mask_expert3.sum())\n","\n","x_expert1 = x_train_experts[mask_expert1][:num_samples_per_expert]\n","y_expert1 = y_train_experts[mask_expert1][:num_samples_per_expert]\n","\n","x_expert2 = x_train_experts[mask_expert2][:num_samples_per_expert]\n","y_expert2 = y_train_experts[mask_expert2][:num_samples_per_expert]\n","\n","x_expert3 = x_train_experts[mask_expert3][:num_samples_per_expert]\n","y_expert3 = y_train_experts[mask_expert3][:num_samples_per_expert]\n","\n","# Splitting the next half samples for training MoE model and for testing\n","x_remaining = x_data[int(num_samples/2)+1:]\n","y_remaining = y_data[int(num_samples/2)+1:]\n","\n","split = int(0.8 * len(x_remaining))\n","x_train_moe = x_remaining[:split]\n","y_train_moe = y_remaining[:split]\n","\n","x_test = x_remaining[split:]\n","y_test = y_remaining[split:]"]},{"cell_type":"markdown","id":"jo077GLOL3x1","metadata":{"id":"jo077GLOL3x1"},"source":["## Train Each Expert"]},{"cell_type":"code","execution_count":null,"id":"EFbICftDOhQr","metadata":{"id":"EFbICftDOhQr"},"outputs":[],"source":["# Define hidden dimension\n","output_dim = 3\n","hidden_dim = 32\n","\n","epochs = 500\n","learning_rate = 0.001\n","\n","# Instantiate the experts\n","expert1 = Expert(input_dim, hidden_dim, output_dim)\n","expert2 = Expert(input_dim, hidden_dim, output_dim)\n","expert3 = Expert(input_dim, hidden_dim, output_dim)\n","\n","# Set up loss\n","criterion = nn.CrossEntropyLoss()\n","\n","# Optimizers for experts\n","optimizer_expert1 = optim.Adam(expert1.parameters(), lr=learning_rate)\n","optimizer_expert2 = optim.Adam(expert2.parameters(), lr=learning_rate)\n","optimizer_expert3 = optim.Adam(expert3.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":null,"id":"xBirrtKuOtVV","metadata":{"id":"xBirrtKuOtVV"},"outputs":[],"source":["# Training loop for expert 1\n","for epoch in range(epochs):\n","    optimizer_expert1.zero_grad()\n","    outputs_expert1 = expert1(x_expert1)\n","    loss_expert1 = criterion(outputs_expert1, y_expert1)\n","    loss_expert1.backward()\n","    optimizer_expert1.step()\n","\n","# Training loop for expert 2\n","for epoch in range(epochs):\n","    optimizer_expert2.zero_grad()\n","    outputs_expert2 = expert2(x_expert2)\n","    loss_expert2 = criterion(outputs_expert2, y_expert2)\n","    loss_expert2.backward()\n","    optimizer_expert2.step()\n","\n","# Training loop for expert 3\n","for epoch in range(epochs):\n","    optimizer_expert3.zero_grad()\n","    outputs_expert3 = expert3(x_expert3)\n","    loss_expert3 = criterion(outputs_expert3, y_expert3)\n","    loss_expert3.backward()\n","    optimizer_expert3.step()"]},{"cell_type":"markdown","id":"aQPUeTU6MHDA","metadata":{"id":"aQPUeTU6MHDA"},"source":["## Train MoE"]},{"cell_type":"code","execution_count":null,"id":"208f3673-a3aa-4e1f-b55e-d53efa7d3ed2","metadata":{"id":"208f3673-a3aa-4e1f-b55e-d53efa7d3ed2"},"outputs":[],"source":["# Create the MoE model with the trained experts\n","moe_model = MoE([expert1, expert2, expert3])\n","\n","# Train the MoE model\n","optimizer_moe = optim.Adam(moe_model.parameters(), lr=learning_rate)\n","for epoch in range(epochs):\n","    optimizer_moe.zero_grad()\n","    outputs_moe = moe_model(x_train_moe)\n","    loss_moe = criterion(outputs_moe, y_train_moe)\n","    loss_moe.backward()\n","    optimizer_moe.step()"]},{"cell_type":"markdown","id":"xHEVbCttMKXy","metadata":{"id":"xHEVbCttMKXy"},"source":["## Evaluate All Models and Compare Accuracies"]},{"cell_type":"code","execution_count":null,"id":"5ac480d5-2a8d-4b77-9223-f7ac0feedc30","metadata":{"id":"5ac480d5-2a8d-4b77-9223-f7ac0feedc30"},"outputs":[],"source":["# Evaluate all models\n","def evaluate(model, x, y):\n","    with torch.no_grad():\n","        outputs = model(x)\n","        _, predicted = torch.max(outputs, 1)\n","        correct = (predicted == y).sum().item()\n","        accuracy = correct / len(y)\n","    return accuracy\n","\n","accuracy_expert1 = evaluate(expert1, x_test, y_test)\n","accuracy_expert2 = evaluate(expert2, x_test, y_test)\n","accuracy_expert3 = evaluate(expert3, x_test, y_test)\n","accuracy_moe = evaluate(moe_model, x_test, y_test)"]},{"cell_type":"code","execution_count":null,"id":"3c643949-3445-42df-ad02-ff4f945fb601","metadata":{"id":"3c643949-3445-42df-ad02-ff4f945fb601","outputId":"d16f034f-c78c-4de5-e9a8-9edb573fa78d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Expert 1 Accuracy: 0.474\n","Expert 2 Accuracy: 0.534\n","Expert 3 Accuracy: 0.55\n","Mixture of Experts Accuracy: 0.666\n"]}],"source":["# Print Accuracy for Each Expert\n","print(\"Expert 1 Accuracy:\", accuracy_expert1)\n","print(\"Expert 2 Accuracy:\", accuracy_expert2)\n","print(\"Expert 3 Accuracy:\", accuracy_expert3)\n","print(\"Mixture of Experts Accuracy:\", accuracy_moe)"]}],"metadata":{"colab":{"collapsed_sections":["q-IoPpS1KktS","BBisRRcOKxCQ"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":5}
